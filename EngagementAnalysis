
!pip install pandas numpy matplotlib seaborn plotly geopandas faker wordcloud
!pip install --upgrade plotly

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import random
from faker import Faker
from collections import Counter
import warnings
warnings.filterwarnings('ignore')


from google.colab import drive
drive.mount('/content/drive')


fake = Faker('id_ID')
np.random.seed(42)
random.seed(42)

# generate data engagement
def generate_realistic_engagement_data(df):
    """Generate data engagement yang realistis berdasarkan sentimen"""
    
    print("ğŸ­ Generating realistic engagement data...")
    
    n = len(df)
    
    # Generate engagement metrics berdasarkan sentimen
    for idx, row in df.iterrows():
        sentiment = row.get('sentiment', 'netral')
        
        # Base engagement berdasarkan sentimen
        if sentiment == 'positif':
            likes = random.randint(50, 500)
            comments = random.randint(5, 100)
            shares = random.randint(2, 50)
            views = random.randint(500, 5000)
        elif sentiment == 'negatif':
            likes = random.randint(10, 200)
            comments = random.randint(10, 150)  # More comments for negative content
            shares = random.randint(1, 30)
            views = random.randint(300, 3000)
        else:  # netral
            likes = random.randint(20, 300)
            comments = random.randint(3, 80)
            shares = random.randint(1, 20)
            views = random.randint(400, 4000)
        
        # Add some randomness
        likes += random.randint(-20, 20)
        comments += random.randint(-5, 5)
        shares += random.randint(-3, 3)
        
        # Ensure minimum values
        df.at[idx, 'likes'] = max(0, likes)
        df.at[idx, 'comments'] = max(0, comments)
        df.at[idx, 'shares'] = max(0, shares)
        df.at[idx, 'views'] = max(0, views)
    
    return df


def generate_comprehensive_hypothetical_data(df):
    """Generate data"""
    
    print("ğŸ­ Generating comprehensive hypothetical data...")
    
    n = len(df)
    
    # Generate usernames jika tidak ada
    if 'username' not in df.columns:
        df['username'] = [fake.user_name() for _ in range(n)]
    
    # Generate dates untuk day-to-day analysis
    start_date = datetime(2024, 1, 1)
    df['date'] = [start_date + timedelta(days=random.randint(0, 90)) for _ in range(n)]
    df['date'] = pd.to_datetime(df['date'])
    
    # Generate gender data dengan distribusi realistis
    genders = ['Male', 'Female', 'Non-binary']
    gender_weights = [0.45, 0.50, 0.05]  # Distribusi gender
    df['gender'] = [random.choices(genders, weights=gender_weights, k=1)[0] for _ in range(n)]
    
    # Generate interests data 
    interests = ['Technology', 'Fashion', 'Sports', 'Food', 'Travel', 
                'Music', 'Gaming', 'Education', 'Health', 'Business']
    interest_weights = [25, 15, 12, 18, 10, 8, 5, 4, 2, 1]  # Weighted distribution
    df['interest'] = [random.choices(interests, weights=interest_weights, k=1)[0] for _ in range(n)]
    
    # Generate locations data (kota-kota Indonesia dengan distribusi populasi)
    indonesian_cities = [
        'Jakarta', 'Surabaya', 'Bandung', 'Medan', 'Semarang',
        'Yogyakarta', 'Makassar', 'Denpasar', 'Palembang', 'Malang',
        'Bogor', 'Surakarta', 'Bekasi', 'Tangerang', 'Depok'
    ]
    city_weights = [30, 15, 12, 10, 8, 7, 6, 5, 4, 3, 2, 2, 2, 2, 1]  # Berdasarkan populasi
    df['location'] = [random.choices(indonesian_cities, weights=city_weights, k=1)[0] for _ in range(n)]
    
    # Generate follower counts dengan distribusi (beberapa influencer, banyak regular users)
    follower_counts = []
    for _ in range(n):
        if random.random() < 0.05:  # 5% influencers
            followers = random.randint(10000, 1000000)
        elif random.random() < 0.2:  # 15% micro-influencers
            followers = random.randint(1000, 10000)
        else:  # 80% regular users
            followers = random.randint(100, 1000)
        follower_counts.append(followers)
    
    df['follower_count'] = follower_counts
    
    # Generate engagement metrics yang realistis
    df = generate_realistic_engagement_data(df)
    
    print("âœ… Comprehensive hypothetical data generation completed!")
    return df

# analisis Day-to-day Engage User
def analyze_daily_engagement(df):
    """Analisis engagement harian"""
    
    print("ğŸ“… Analyzing day-to-day engagement...")
    
    if 'date' not in df.columns:
        print("âš ï¸  Kolom 'date' tidak ditemukan untuk analisis harian")
        return None
    
    df['date'] = pd.to_datetime(df['date'])
    df['day'] = df['date'].dt.date
    df['day_of_week'] = df['date'].dt.day_name()
    df['hour'] = df['date'].dt.hour
    
    # Calculate total engagement
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    # Daily engagement metrics
    daily_engagement = df.groupby('day').agg({
        'likes': 'sum',
        'comments': 'sum',
        'shares': 'sum',
        'views': 'sum',
        'username': 'count'
    }).rename(columns={'username': 'post_count'}).reset_index()
    
    daily_engagement['total_engagement'] = (
        daily_engagement['likes'] + 
        daily_engagement['comments'] * 2 + 
        daily_engagement['shares'] * 3
    )
    
    #Engagement by day of week
    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    df['day_of_week'] = pd.Categorical(df['day_of_week'], categories=weekday_order, ordered=True)
    
    weekday_engagement = df.groupby('day_of_week').agg({
        'likes': 'mean',
        'comments': 'mean',
        'shares': 'mean',
        'total_engagement': 'mean'
    }).reset_index()
    
    # Best performing days
    best_day = daily_engagement.loc[daily_engagement['total_engagement'].idxmax()]
    
    return {
        'daily_engagement': daily_engagement,
        'weekday_engagement': weekday_engagement,
        'best_day': best_day,
        'total_days': len(daily_engagement)
    }

#analisis Engaged User By Gender
def analyze_engagement_by_gender(df):
    """Analisis engagement berdasarkan gender"""
    
    print("ğŸ‘¥ Analyzing engagement by gender...")
    
    if 'gender' not in df.columns:
        print("âš ï¸  Kolom 'gender' tidak ditemukan")
        return None
    
    # Calculate total engagement first
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    gender_analysis = df.groupby('gender').agg({
        'likes': ['sum', 'mean', 'count'],
        'comments': ['sum', 'mean'],
        'shares': ['sum', 'mean'],
        'total_engagement': ['sum', 'mean']
    }).round(2)
    
    # Engagement rate by gender
    gender_stats = df.groupby('gender').size()
    engagement_by_gender = df.groupby('gender')['total_engagement'].sum()
    
    return {
        'gender_analysis': gender_analysis,
        'gender_distribution': gender_stats,
        'engagement_by_gender': engagement_by_gender
    }

# Fungsi untuk analisis Engaged User By Interest
def analyze_engagement_by_interest(df):
    """Analisis engagement berdasarkan interest"""
    
    print("ğŸ¯ Analyzing engagement by interest...")
    
    if 'interest' not in df.columns:
        print("âš ï¸  Kolom 'interest' tidak ditemukan")
        return None
    
    # Calculate total engagement first
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    interest_analysis = df.groupby('interest').agg({
        'likes': ['sum', 'mean', 'count'],
        'comments': ['sum', 'mean'],
        'shares': ['sum', 'mean'],
        'total_engagement': ['sum', 'mean']
    }).round(2)
    
    # Top interests by engagement
    top_interests = interest_analysis[('total_engagement', 'sum')].nlargest(5)
    
    return {
        'interest_analysis': interest_analysis,
        'top_interests': top_interests,
        'interest_distribution': df['interest'].value_counts()
    }

# Fungsi untuk analisis Engaged User By Locations
def analyze_engagement_by_location(df):
    """Analisis engagement berdasarkan lokasi"""
    
    print("ğŸ“ Analyzing engagement by location...")
    
    if 'location' not in df.columns:
        print("âš ï¸  Kolom 'location' tidak ditemukan")
        return None
    
    # Calculate total engagement first
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    location_analysis = df.groupby('location').agg({
        'likes': ['sum', 'mean', 'count'],
        'comments': ['sum', 'mean'],
        'shares': ['sum', 'mean'],
        'total_engagement': ['sum', 'mean'],
        'username': 'nunique'
    }).round(2)
    
    location_analysis.columns = ['_'.join(col).strip() for col in location_analysis.columns.values]
    
    # Top locations by engagement
    top_locations = location_analysis['total_engagement_sum'].nlargest(5)
    
    return {
        'location_analysis': location_analysis,
        'top_locations': top_locations,
        'user_count_by_location': location_analysis['username_nunique']
    }

# Fungsi untuk analisis Username Top Talker
def analyze_top_talkers(df):
    """Analisis top talker berdasarkan engagement"""
    
    print("ğŸ—£ï¸ Analyzing top talkers...")
    
    if 'username' not in df.columns:
        print("âš ï¸  Kolom 'username' tidak ditemukan")
        return None
    
    # Calculate total engagement first
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    top_talkers = df.groupby('username').agg({
        'comments': 'sum',
        'likes': 'sum',
        'shares': 'sum',
        'total_engagement': 'sum',
        'date': 'count'
    }).rename(columns={'date': 'post_count'}).sort_values('comments', ascending=False)
    
    # Top 10 talkers by comments
    top_10_talkers = top_talkers.head(10)
    
    return {
        'top_talkers': top_talkers,
        'top_10_talkers': top_10_talkers
    }

# analisis Top Influencer
def analyze_top_influencers(df):
    """Analisis top influencer berdasarkan engagement rate"""
    
    print("ğŸŒŸ Analyzing top influencers...")
    
    if 'username' not in df.columns or 'follower_count' not in df.columns:
        print("âš ï¸  Kolom 'username' atau 'follower_count' tidak ditemukan")
        return None
    
    # Calculate total engagement first
    df['total_engagement'] = df['likes'] + df['comments'] * 2 + df['shares'] * 3
    
    influencer_analysis = df.groupby('username').agg({
        'total_engagement': 'sum',
        'follower_count': 'first',
        'post_count': 'count'
    }).reset_index()
    
    # Calculate engagement rate 
    influencer_analysis['engagement_rate'] = (
        (influencer_analysis['total_engagement'] / influencer_analysis['follower_count']) * 1000
    ).round(2)
    
    # Filter influencers dengan minimal 100 followers
    influencer_analysis = influencer_analysis[influencer_analysis['follower_count'] >= 100]
    
    # Top influencers by engagement rate
    top_influencers_by_rate = influencer_analysis.nlargest(10, 'engagement_rate')
    
    # Top influencers by total engagement
    top_influencers_by_engagement = influencer_analysis.nlargest(10, 'total_engagement')
    
    return {
        'influencer_analysis': influencer_analysis,
        'top_influencers_by_rate': top_influencers_by_rate,
        'top_influencers_by_engagement': top_influencers_by_engagement,
        'avg_engagement_rate': influencer_analysis['engagement_rate'].mean()
    }

# Fungsi untuk visualisasi komprehensif
def create_comprehensive_visualizations(df, analysis_results):
    """Membuat visualisasi komprehensif untuk semua analisis"""
    
    print("ğŸ“Š Creating comprehensive visualizations...")
    
    fig = make_subplots(
        rows=3, cols=2,
        subplot_titles=(
            'Daily Engagement Trend',
            'Engagement by Gender',
            'Engagement by Interest',
            'Engagement by Location',
            'Top Talkers Analysis',
            'Top Influencers'
        ),
        specs=[[{"type": "scatter"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}]]
    )
    
    # 1. Daily Engagement Trend
    daily_data = analysis_results['daily_analysis']['daily_engagement']
    fig.add_trace(
        go.Scatter(x=daily_data['day'], y=daily_data['total_engagement'], 
                  mode='lines+markers', name='Daily Engagement'),
        row=1, col=1
    )
    
    # 2. Engagement by Gender
    gender_data = analysis_results['gender_analysis']['engagement_by_gender']
    fig.add_trace(
        go.Bar(x=gender_data.index, y=gender_data.values, name='Engagement by Gender'),
        row=1, col=2
    )
    
    # 3. Engagement by Interest
    interest_data = analysis_results['interest_analysis']['top_interests']
    fig.add_trace(
        go.Bar(x=interest_data.index, y=interest_data.values, name='Top Interests'),
        row=2, col=1
    )
    
    # 4. Engagement by Location
    location_data = analysis_results['location_analysis']['top_locations']
    fig.add_trace(
        go.Bar(x=location_data.index, y=location_data.values, name='Top Locations'),
        row=2, col=2
    )
    
    # 5. Top Talkers
    talker_data = analysis_results['top_talkers']['top_10_talkers']['comments'].head(5)
    fig.add_trace(
        go.Bar(x=talker_data.values, y=talker_data.index, orientation='h', name='Top Talkers'),
        row=3, col=1
    )
    
    # 6. Top Influencers
    influencer_data = analysis_results['top_influencers']['top_influencers_by_rate']['engagement_rate'].head(5)
    fig.add_trace(
        go.Bar(x=influencer_data.values, y=influencer_data.index, orientation='h', name='Top Influencers'),
        row=3, col=2
    )
    
    fig.update_layout(height=1200, showlegend=False, title_text="Comprehensive Engagement Analysis Dashboard")
    fig.show()

# Fungsi utama untuk analisis engagement komprehensif
def perform_advanced_engagement_analysis(file_path):
    """Fungsi utama untuk analisis engagement advanced"""
    
    print("ğŸš€ MEMULAI ANALISIS ENGAGEMENT KOMPREHENSIF")
    print("="*60)
    
    # Baca file
    try:
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        elif file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            raise ValueError("Format file tidak didukung")
    except Exception as e:
        print(f"âŒ Error membaca file: {e}")
        return None, None
    
    print(f"âœ… File berhasil dibaca. Shape: {df.shape}")
    
    # Generate comprehensive hypothetical data
    df = generate_comprehensive_hypothetical_data(df)
    
    # Lakukan semua analisis
    analysis_results = {}
    
    print("\n" + "="*60)
    print("ğŸ“Š MELAKUKAN ANALISIS KOMPREHENSIF")
    print("="*60)
    
    # 1. Daily Engagement Analysis
    analysis_results['daily_analysis'] = analyze_daily_engagement(df)
    
    # 2. Gender Analysis
    analysis_results['gender_analysis'] = analyze_engagement_by_gender(df)
    
    # 3. Interest Analysis
    analysis_results['interest_analysis'] = analyze_engagement_by_interest(df)
    
    # 4. Location Analysis
    analysis_results['location_analysis'] = analyze_engagement_by_location(df)
    
    # 5. Top Talkers Analysis
    analysis_results['top_talkers'] = analyze_top_talkers(df)
    
    # 6. Top Influencers Analysis
    analysis_results['top_influencers'] = analyze_top_influencers(df)
    
    # Tampilkan hasil
    print("\n" + "="*60)
    print("ğŸ¯ HASIL ANALISIS ENGAGEMENT KOMPREHENSIF")
    print("="*60)
    
    # Display key insights
    print("\nğŸ“ˆ KEY INSIGHTS:")
    
    # Daily insights
    if analysis_results['daily_analysis']:
        best_day = analysis_results['daily_analysis']['best_day']
        print(f"ğŸ“… Best Performing Day: {best_day['day']} with {best_day['total_engagement']:,.0f} engagement")
    
    # Gender insights
    if analysis_results['gender_analysis']:
        gender_engagement = analysis_results['gender_analysis']['engagement_by_gender']
        top_gender = gender_engagement.idxmax()
        print(f"ğŸ‘¥ Top Engaging Gender: {top_gender} with {gender_engagement.max():,.0f} total engagement")
    
    # Interest insights
    if analysis_results['interest_analysis']:
        top_interest = analysis_results['interest_analysis']['top_interests'].idxmax()
        top_engagement = analysis_results['interest_analysis']['top_interests'].max()
        print(f"ğŸ¯ Top Interest: {top_interest} with {top_engagement:,.0f} total engagement")
    
    # Location insights
    if analysis_results['location_analysis']:
        top_location = analysis_results['location_analysis']['top_locations'].idxmax()
        top_loc_engagement = analysis_results['location_analysis']['top_locations'].max()
        print(f"ğŸ“ Top Location: {top_location} with {top_loc_engagement:,.0f} total engagement")
    
    # Top talker insights
    if analysis_results['top_talkers']:
        top_talker = analysis_results['top_talkers']['top_10_talkers'].index[0]
        talker_comments = analysis_results['top_talkers']['top_10_talkers'].iloc[0]['comments']
        print(f"ğŸ—£ï¸ Top Talker: {top_talker} with {talker_comments} comments")
    
    # Influencer insights
    if analysis_results['top_influencers']:
        top_influencer = analysis_results['top_influencers']['top_influencers_by_rate'].iloc[0]['username']
        influencer_rate = analysis_results['top_influencers']['top_influencers_by_rate'].iloc[0]['engagement_rate']
        influencer_followers = analysis_results['top_influencers']['top_influencers_by_rate'].iloc[0]['follower_count']
        print(f"ğŸŒŸ Top Influencer: {top_influencer} with {influencer_rate} engagement rate per 1000 followers ({influencer_followers:,.0f} followers)")
    
    # Visualisasi
    print("\n" + "="*60)
    print("ğŸ“Š VISUALISASI DATA")
    print("="*60)
    
    create_comprehensive_visualizations(df, analysis_results)
    
    # Detailed reports
    print("\n" + "="*60)
    print("ğŸ“‹ LAPORAN DETAIL")
    print("="*60)
    
    # Print detailed tables
    print("\nğŸ† TOP 5 INFLUENCERS BY ENGAGEMENT RATE:")
    if analysis_results['top_influencers']:
        influencer_df = analysis_results['top_influencers']['top_influencers_by_rate'].head(5).copy()
        influencer_df['engagement_rate'] = influencer_df['engagement_rate'].round(2)
        influencer_df['follower_count'] = influencer_df['follower_count'].apply(lambda x: f"{x:,.0f}")
        print(influencer_df[['username', 'engagement_rate', 'follower_count', 'total_engagement']])
    
    print("\nğŸ—£ï¸ TOP 5 TALKERS:")
    if analysis_results['top_talkers']:
        talker_df = analysis_results['top_talkers']['top_10_talkers'].head(5).copy()
        talker_df = talker_df[['comments', 'likes', 'shares', 'total_engagement']]
        print(talker_df)
    
    print("\nğŸ¯ TOP 5 INTERESTS BY ENGAGEMENT:")
    if analysis_results['interest_analysis']:
        interest_df = analysis_results['interest_analysis']['top_interests'].head(5).reset_index()
        interest_df.columns = ['Interest', 'Total Engagement']
        interest_df['Total Engagement'] = interest_df['Total Engagement'].apply(lambda x: f"{x:,.0f}")
        print(interest_df)
    
    # Simpan hasil
    output_file = file_path.replace('.', '_advanced_engagement_analysis.')
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ Hasil analisis disimpan sebagai: {output_file}")
    
    return df, analysis_results

# Main execution
if __name__ == "__main__":
    # Path ke file
    file_path = "/content/sample_data/analyzed_data.csv"
    
    
    import os
    if not os.path.exists(file_path):
        print("ğŸ“ File default tidak ditemukan. Silakan upload file hasil analisis sentimen.")
        from google.colab import files
        uploaded = files.upload()
        
        if uploaded:
            file_path = list(uploaded.keys())[0]
            print(f"ğŸ“‚ File '{file_path}' berhasil diupload!")
        else:
            file_path = input("ğŸ“ Masukkan path file hasil analisis sentimen: ")
    
    # Jalankan analisis
    print("ğŸš€ Memulai analisis engagement komprehensif...")
    result_df, analysis_results = perform_advanced_engagement_analysis(file_path)
    
    if result_df is not None:
        total_engagement = result_df['likes'].sum() + result_df['comments'].sum() * 2 + result_df['shares'].sum() * 3
        
        print("\nğŸ‰ ANALISIS SELESAI!")
        print("="*60)
        print(f"ğŸ“Š Total data dianalisis: {len(result_df)}")
        print(f"â­ Total engagement: {total_engagement:,.0f}")
        print(f"â¤ï¸  Total likes: {result_df['likes'].sum():,.0f}")
        print(f"ğŸ’¬ Total comments: {result_df['comments'].sum():,.0f}")
        print(f"ğŸ”„ Total shares: {result_df['shares'].sum():,.0f}")
        print(f"ğŸ‘¥ Unique users: {result_df['username'].nunique()}")
        print(f"ğŸ“ Unique locations: {result_df['location'].nunique()}")
        print(f"ğŸ¯ Unique interests: {result_df['interest'].nunique()}")
        print("="*60)
